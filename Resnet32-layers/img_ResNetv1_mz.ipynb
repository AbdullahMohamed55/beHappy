{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from numpy import genfromtxt\n",
    "\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 48\n",
    "DATA_SIZE = 35887\n",
    "NUM_CLASSES = 10\n",
    "FILE_NAME = \"fer2013/fer2013.csv\"\n",
    "\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "#from lasagne.layers.dnn import Conv2DDNNLayer as ConvLayer\n",
    "from lasagne.layers import ElemwiseSumLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import GlobalPoolLayer\n",
    "from lasagne.layers import PadLayer\n",
    "from lasagne.layers import ExpressionLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.nonlinearities import softmax, rectify\n",
    "from lasagne.layers import batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(input_var=None, n=5):\n",
    "    \n",
    "    # create a residual learning building block with two stacked 3x3 convlayers as in paper\n",
    "    def residual_block(l, increase_dim=False, projection=False):\n",
    "        input_num_filters = l.output_shape[1]\n",
    "        if increase_dim:\n",
    "            first_stride = (2,2)\n",
    "            out_num_filters = input_num_filters*2\n",
    "        else:\n",
    "            first_stride = (1,1)\n",
    "            out_num_filters = input_num_filters\n",
    "\n",
    "        stack_1 = batch_norm(ConvLayer(l, num_filters=out_num_filters, filter_size=(3,3), stride=first_stride, nonlinearity=rectify, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "        stack_2 = batch_norm(ConvLayer(stack_1, num_filters=out_num_filters, filter_size=(3,3), stride=(1,1), nonlinearity=None, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "        \n",
    "        # add shortcut connections  \n",
    "        if increase_dim:\n",
    "            if projection:\n",
    "                # projection shortcut, as option B in paper\n",
    "                projection = batch_norm(ConvLayer(l, num_filters=out_num_filters, filter_size=(1,1), stride=(2,2), nonlinearity=None, pad='same', b=None, flip_filters=False))\n",
    "                block = NonlinearityLayer(ElemwiseSumLayer([stack_2, projection]),nonlinearity=rectify)\n",
    "            else:\n",
    "                # identity shortcut, as option A in paper\n",
    "                identity = ExpressionLayer(l, lambda X: X[:, :, ::2, ::2], lambda s: (s[0], s[1], s[2]//2, s[3]//2))\n",
    "                padding = PadLayer(identity, [out_num_filters//4,0,0], batch_ndim=1)\n",
    "                block = NonlinearityLayer(ElemwiseSumLayer([stack_2, padding]),nonlinearity=rectify)\n",
    "        else:\n",
    "            block = NonlinearityLayer(ElemwiseSumLayer([stack_2, l]),nonlinearity=rectify)\n",
    "        \n",
    "        return block\n",
    "\n",
    "    # Building the network\n",
    "    l_in = InputLayer(shape=(None, 1, 48, 48), input_var=input_var)\n",
    "\n",
    "    # first layer, output is 16 x 32 x 32\n",
    "    l = batch_norm(ConvLayer(l_in, num_filters=16, filter_size=(3,3), stride=(1,1), nonlinearity=rectify, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "    \n",
    "    # first stack of residual blocks, output is 16 x 32 x 32\n",
    "    for _ in range(n):\n",
    "        l = residual_block(l)\n",
    "\n",
    "    # second stack of residual blocks, output is 32 x 16 x 16\n",
    "    l = residual_block(l, increase_dim=True)\n",
    "    for _ in range(1,n):\n",
    "        l = residual_block(l)\n",
    "\n",
    "\n",
    "    # third stack of residual blocks, output is 64 x 8 x 8\n",
    "    l = residual_block(l, increase_dim=True)\n",
    "    for _ in range(1,n):\n",
    "        l = residual_block(l)\n",
    "    \n",
    "    # average pooling\n",
    "    l = GlobalPoolLayer(l) ##!!!!!\n",
    "    #l= lasagne.layers.dropout_channels(l,p=0.5)\n",
    "\n",
    "    #l = batch_norm(DenseLayer(l, num_units = 16, W=lasagne.init.HeNormal(gain = 'relu'), nonlinearity=rectify))\n",
    "    #l= lasagne.layers.MaxPool2DLayer(l, 2,pad=(0, 0), ignore_border=True) \n",
    "    # fully connected layer\n",
    "    network = DenseLayer(\n",
    "            l, num_units= 7,\n",
    "            W=lasagne.init.HeNormal(),\n",
    "            nonlinearity=softmax)\n",
    "\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "number of parameters in model: 463671\n"
     ]
    }
   ],
   "source": [
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "# Create neural network model\n",
    "print(\"Building model and compiling functions...\")\n",
    "network = build_cnn(input_var, 5)\n",
    "print(\"number of parameters in model: %d\" % lasagne.layers.count_params(network, trainable=True))\n",
    "\n",
    "\n",
    "# Create a loss expression for validation/testing\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                        target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                  dtype=theano.config.floatX)\n",
    "\n",
    "#test_acc1 = lasagne.objectives.categorical_accuracy(test_prediction, target_var, top_k=1)\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var],test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.load('66.65.npz') as f:\n",
    "             param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(network, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#fig = plt.figure()\n",
    "#cv2.destroyAllWindows()\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#while(True):\n",
    "    # Capture frame-by-frame\n",
    "   # ret, frame = cap.read()\n",
    "    \n",
    "#start here\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "image_path = 'testImg/test5.jpg'\n",
    "#os.system('pwd')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "frame = cv2.imread(image_path,cv2.IMREAD_UNCHANGED)\n",
    "#happy = cv2.imread('emojis/happy.png', cv2.IMREAD_UNCHANGED)\n",
    "#happy = cv2.cvtColor(happy, cv2.COLOR_BGRA2RGBA)\n",
    "#cv2.imshow('hi',happy)\n",
    "#cv2.waitKey(0)\n",
    "#plt.imshow(happy)\n",
    "#print len(frame)\n",
    "img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "facelocs = detector(img, 3)\n",
    "faces = np.ndarray(shape=(1, 48*48), dtype=np.uint8)\n",
    "for box in facelocs:\n",
    "    face = gray[box.top(): box.bottom(), box.left(): box.right()]\n",
    "    face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_CUBIC)\n",
    "    face = np.array(face)\n",
    "    face = np.reshape(face, 48*48)\n",
    "    faces = np.vstack((faces, face))\n",
    "faces = np.delete(faces, 0, 0)\n",
    "if faces.shape[0]!=0: \n",
    "    modes = np.array(['emojis/happy.png','emojis/disgust.png','emojis/fear.png','emojis/happy.png',\n",
    "                  'emojis/sad.png','emojis/surprised.png','emojis/neutral.png'])\n",
    "    faces = faces.reshape((faces.shape[0], 1, DIM, DIM))\n",
    "    #print faces.shape\n",
    "    net_out = val_fn(faces)   \n",
    "    preds = np.argmax(net_out, axis=-1)\n",
    "i=0\n",
    "for box in facelocs:\n",
    "    shapes = predictor(img, box)\n",
    "\n",
    "    emoji = cv2.resize(cv2.cvtColor(cv2.imread(modes[preds[i]], -1), cv2.COLOR_BGRA2RGBA), (box.right() - box.left(), box.bottom() - box.top()), interpolation = cv2.INTER_CUBIC)\n",
    "    rows, cols, d = emoji.shape\n",
    "    #plt.imshow(emoji)\n",
    "\n",
    "    diag = np.sqrt((box.bottom() - box.top())**2 + (box.right() - box.left())**2)\n",
    "    wexp = (diag - (box.right() - box.left()))/2\n",
    "    hexp = (diag - (box.bottom() - box.top()))/2\n",
    "    wexp = int(wexp)\n",
    "    hexp = int(hexp)\n",
    "    emoji = cv2.copyMakeBorder(emoji, hexp, hexp, wexp, wexp, cv2.BORDER_REPLICATE)\n",
    "    #plt.imshow(emoji)\n",
    "\n",
    "    src = np.array([(cols*(20.0/512.0) + wexp, rows*(200.0/512.0) + hexp), (cols*(256.0/512.0)+ wexp, rows*(495.0/512.0)+ hexp), (cols*(492.0/512.0)+ wexp, rows*(200.0/512.0)+ hexp)])\n",
    "    #src = np.array([(20, 200), (256, 495), (492, 200)])\n",
    "    src = np.uint8(src)\n",
    "    src = np.float32(src)\n",
    "    dest = np.array([(shapes.part(0).x - box.left()+ wexp, shapes.part(0).y - box.top()+ hexp),(shapes.part(8).x-box.left()+ wexp, shapes.part(8).y - box.top()+ hexp),(shapes.part(16).x - box.left()+ wexp, shapes.part(16).y - box.top()+ hexp)])\n",
    "    dest = np.float32(dest)\n",
    "    rows, cols, d = emoji.shape\n",
    "    trans = cv2.getAffineTransform(src,dest)\n",
    "    #plt.imshow(trans)\n",
    "    #print trans\n",
    "    emoji = cv2.warpAffine(emoji, trans, (cols, rows))\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    #pint(emoji.shape)\n",
    "    for c in range(0,3):\n",
    "        img[box.top() - hexp: box.bottom() + hexp, box.left() - wexp: box.right() + wexp, c] = emoji[:,:,c] * (emoji[:,:,3]/255.0) + img[box.top() - hexp: box.bottom() + hexp, box.left() - wexp: box.right() + wexp, c] * (1.0 - emoji[:,:,3]/255.0)\n",
    "    plt.imsave('result5.jpg',img)\n",
    "\n",
    "        #cv2.imshow('frame',img)\n",
    "        \n",
    "    #end here\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "\n",
    "    #cv2.imshow('frame',gray)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "   #     break\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
