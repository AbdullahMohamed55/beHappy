{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from numpy import genfromtxt\n",
    "from lasagne.layers import batch_norm ,dropout,DenseLayer\n",
    "\n",
    "conv = lasagne.layers.Conv2DLayer\n",
    "pool = lasagne.layers.MaxPool2DLayer\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001\n",
    "DIM = 48\n",
    "DATA_SIZE = 35887\n",
    "NUM_CLASSES = 10\n",
    "FILE_NAME = \"fer2013/fer2013.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters in model: 2388970\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_width, input_height, output_dim):\n",
    "    ini = lasagne.init.HeUniform(gain='relu')\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, input_width, input_height),)\n",
    "    \n",
    "    \n",
    "    #class_l5 = pool(class_l4, pool_size=(2, 2))\n",
    "    #class_b1 = lasagne.layers.batch_norm(class_l1) #batchnorm\n",
    "    #class_d1 = lasagne.layers.DropoutLayer(class_l2) #  dropout\n",
    "    \n",
    "    # Classi32fication network\n",
    "    #stack_1 = batch_norm(ConvLayer(l, num_filters=out_num_filters,filter_size=(3,3), stride=first_stride, nonlinearity=rectify, pad='same', W=lasagne.init.HeNormal(gain='relu'), flip_filters=False))\n",
    "    class_l1 = batch_norm(conv(\n",
    "        l_in,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d0 = dropout(class_l1,p=0.3)\n",
    "    \n",
    "    class_l2 = batch_norm(conv(\n",
    "        class_d0,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d1 = dropout(class_l2,p=0.3)\n",
    "    \n",
    "    \n",
    "    class_l3 = batch_norm(conv(\n",
    "        class_d1,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d2 = dropout(class_l3,p=0.35)\n",
    "    \n",
    "    \n",
    "    class_l4 = batch_norm(conv(\n",
    "        class_d2,\n",
    "        num_filters=32,pad='same',\n",
    "        filter_size=(3, 3),\n",
    "        #filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    ))\n",
    "    class_d3 = dropout(class_l4,p=0.2)   \n",
    "    #class_l5 = pool(class_l4, pool_size=(2, 2))\n",
    "    \n",
    "    \n",
    "    class_l1_dens = batch_norm(DenseLayer(\n",
    "        class_d3,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d1_dens = dropout(class_l1_dens,0.3)\n",
    "    \n",
    "    class_l2_dens = batch_norm(DenseLayer(\n",
    "        class_d1_dens,\n",
    "        num_units=32,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=ini,\n",
    "    )) \n",
    "    class_d2_dens = dropout(class_l2_dens,p=0.2)\n",
    "    \n",
    "    l_out = DenseLayer(\n",
    "        class_d2_dens,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=ini,\n",
    "    )\n",
    "    return l_out\n",
    "\n",
    "model= build_model(DIM, DIM, NUM_CLASSES)\n",
    "print(\"number of parameters in model: %d\" % lasagne.layers.count_params(model, trainable=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up the graph in theano\n",
    "sym_x = T.tensor4('sym_x') # a symbolic variable, this is now a 4-D tensor.\n",
    "sym_t = T.ivector('sym_t') # a symbolic variable taking on the value of the target batch.\n",
    "\n",
    "# Retrieve network output\n",
    "train_out = lasagne.layers.get_output(model, sym_x, deterministic=False)\n",
    "eval_out = lasagne.layers.get_output(model, sym_x, deterministic=True)\n",
    "\n",
    "# Retrieve list of all trainable parameters in the network.\n",
    "all_params = lasagne.layers.get_all_params(model, trainable=True)\n",
    "\n",
    "# add weight decay\n",
    "all_layers = lasagne.layers.get_all_layers(model)\n",
    "l2_penalty = lasagne.regularization.regularize_layer_params(all_layers, lasagne.regularization.l2) * 0.001\n",
    "\n",
    "\n",
    "#reg2 = lasagne.regularization.l2(train_out)\n",
    "#reg = lasagne.regularization.l1( train_out )\n",
    "cost = lasagne.objectives.categorical_crossentropy(train_out+1e-8, sym_t).mean()\n",
    "\n",
    "# Let Theano do its magic and get all the gradients we need for training\n",
    "all_grads = T.grad(cost, all_params)\n",
    " \n",
    "# Set the update function for parameters \n",
    "# you might wan't to experiment with more advanded update schemes like rmsprob, adadelta etc.\n",
    "sh_lr = theano.shared(lasagne.utils.floatX(LEARNING_RATE))\n",
    "\n",
    "Updates = lasagne.updates.adam(all_grads, all_params, learning_rate=sh_lr)\n",
    "\n",
    "f_eval = theano.function([sym_x],eval_out, on_unused_input='warn')\n",
    "\n",
    "f_train = theano.function([sym_x, sym_t],[cost],updates=Updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with np.load('weights.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values( model, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#fig = plt.figure()\n",
    "#cv2.destroyAllWindows()\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#while(True):\n",
    "    # Capture frame-by-frame\n",
    "   # ret, frame = cap.read()\n",
    "    \n",
    "#start here\n",
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "image_path = 'testImg/test10.jpg'\n",
    "#os.system('pwd')\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "# (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "frame = cv2.imread(image_path,cv2.IMREAD_UNCHANGED)\n",
    "#happy = cv2.imread('emojis/happy.png', cv2.IMREAD_UNCHANGED)\n",
    "#happy = cv2.cvtColor(happy, cv2.COLOR_BGRA2RGBA)\n",
    "#cv2.imshow('hi',happy)\n",
    "#cv2.waitKey(0)\n",
    "#plt.imshow(happy)\n",
    "#print len(frame)\n",
    "img = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "facelocs = detector(img, 3)\n",
    "faces = np.ndarray(shape=(1, 48*48), dtype=np.uint8)\n",
    "for box in facelocs:\n",
    "    face = gray[box.top(): box.bottom(), box.left(): box.right()]\n",
    "    face = cv2.resize(face, (48, 48), interpolation = cv2.INTER_CUBIC)\n",
    "    face = np.array(face)\n",
    "    face = np.reshape(face, 48*48)\n",
    "    faces = np.vstack((faces, face))\n",
    "faces = np.delete(faces, 0, 0)\n",
    "if faces.shape[0]!=0: \n",
    "    modes = np.array(['emojis/happy.png','emojis/disgust.png','emojis/fear.png','emojis/happy.png',\n",
    "                  'emojis/sad.png','emojis/surprised.png','emojis/neutral.png'])\n",
    "    faces = faces.reshape((faces.shape[0], 1, DIM, DIM))\n",
    "    #print faces.shape\n",
    "    net_out = f_eval(faces)   \n",
    "    preds = np.argmax(net_out, axis=-1)\n",
    "i=0\n",
    "for box in facelocs:\n",
    "    shapes = predictor(img, box)\n",
    "\n",
    "    emoji = cv2.resize(cv2.cvtColor(cv2.imread(modes[preds[i]], -1), cv2.COLOR_BGRA2RGBA), (box.right() - box.left(), box.bottom() - box.top()), interpolation = cv2.INTER_CUBIC)\n",
    "    rows, cols, d = emoji.shape\n",
    "    #plt.imshow(emoji)\n",
    "\n",
    "    diag = np.sqrt((box.bottom() - box.top())**2 + (box.right() - box.left())**2)\n",
    "    wexp = (diag - (box.right() - box.left()))/2\n",
    "    hexp = (diag - (box.bottom() - box.top()))/2\n",
    "    wexp = int(wexp)\n",
    "    hexp = int(hexp)\n",
    "    emoji = cv2.copyMakeBorder(emoji, hexp, hexp, wexp, wexp, cv2.BORDER_REPLICATE)\n",
    "    #plt.imshow(emoji)\n",
    "\n",
    "    src = np.array([(cols*(20.0/512.0) + wexp, rows*(200.0/512.0) + hexp), (cols*(256.0/512.0)+ wexp, rows*(495.0/512.0)+ hexp), (cols*(492.0/512.0)+ wexp, rows*(200.0/512.0)+ hexp)])\n",
    "    #src = np.array([(20, 200), (256, 495), (492, 200)])\n",
    "    src = np.uint8(src)\n",
    "    src = np.float32(src)\n",
    "    dest = np.array([(shapes.part(0).x - box.left()+ wexp, shapes.part(0).y - box.top()+ hexp),(shapes.part(8).x-box.left()+ wexp, shapes.part(8).y - box.top()+ hexp),(shapes.part(16).x - box.left()+ wexp, shapes.part(16).y - box.top()+ hexp)])\n",
    "    dest = np.float32(dest)\n",
    "    rows, cols, d = emoji.shape\n",
    "    trans = cv2.getAffineTransform(src,dest)\n",
    "    #plt.imshow(trans)\n",
    "    #print trans\n",
    "    emoji = cv2.warpAffine(emoji, trans, (cols, rows))\n",
    "    i+=1\n",
    "\n",
    "\n",
    "    #pint(emoji.shape)\n",
    "    for c in range(0,3):\n",
    "        img[box.top() - hexp: box.bottom() + hexp, box.left() - wexp: box.right() + wexp, c] = emoji[:,:,c] * (emoji[:,:,3]/255.0) + img[box.top() - hexp: box.bottom() + hexp, box.left() - wexp: box.right() + wexp, c] * (1.0 - emoji[:,:,3]/255.0)\n",
    "    plt.imsave('result3.jpg',img)\n",
    "\n",
    "        #cv2.imshow('frame',img)\n",
    "        \n",
    "    #end here\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "\n",
    "    #cv2.imshow('frame',gray)\n",
    "    #if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "   #     break\n",
    "\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
